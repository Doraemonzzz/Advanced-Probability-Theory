## 2.(弱)大数定律(LLN)

#### 定理7.1.1

$$
设\{X_n\} \ iid,那么存在\{a_n\}使得 \frac{S_n}{n}-a_n \overset{\mathbb P} \to 0 \Leftrightarrow
\lim_{x\to \infty} x \mathbb P (|X_1|>x)= 0
$$

证明：仅证明$\Leftarrow$：$\forall n \ge 1, 1\le k \le n$，定义
$$
X_{nk}\triangleq X_k 1_{\{ |X_k|\le n\}} ,\hat S_n =\sum_{k=1}^n X_{nk}
$$
不难看出$y_k=X_{nk}$独立同分布，则
$$
\begin{aligned}
\frac 1{n^2} \text{Var}(\hat S_n) 
&=\frac 1 {n^2} \sum_{k=1}^n \text{Var}(X_{nk})\\
&\le \frac 1 {n^2} \sum_{k=1}^n\mathbb E[X_{nk}^2] \\
&=  \frac 1 {n} \mathbb E[X_{n1}^2]
\end{aligned}
$$
回顾公式
$$
如果X非负，\mathbb E[X^r] =r\int_{0}^{\infty} x^{r-1}\mathbb P(X>x)  dx
$$
那么对上式取$r=2$可得
$$
\begin{aligned}
\frac 1 {n} \mathbb E[X_{n1}^2] 
&= \frac 2 n  \int_{0}^{\infty} x \mathbb P(|X_{n1}| > x) dx \\
&= \frac 2 n \int_{0}^{n} x \mathbb P(|X_{1}| > x) dx
\end{aligned}
$$
由条件可知
$$
\forall \epsilon >0,\exists N ,\forall n \ge N, \exists x_0,当x> x_0时，\\
x \mathbb P(|X_1| > x) < \epsilon
$$
所以
$$
\begin{aligned}
\frac 1 {n} \mathbb E[X_{n1}^2] 
&= \frac 2 n \int_{0}^{n} x \mathbb P(|X_{1}| > x) dx \\
&=\frac 2 n \int_{0}^{x_0} x \mathbb P(|X_{1}| > x) dx
+\frac 2 n \int_{x_0}^{n} x \mathbb P(|X_{1}| > x) dx\\
\end{aligned}
$$
上述第一项$\to 0$，第二项$< 2\epsilon$，从而
$$
\frac 1{n^2} \text{Var}(\hat S_n)  \to 0
$$
因此
$$
\frac{\hat S_n -\mathbb E [\hat S_n]}{n} \overset{L^2}{\underset{p} \to }0
$$
接下来计算$\mathbb P (|\frac{S_n}{n}- \frac {\mathbb E [\hat S_n]}{n}| \ge \epsilon )$
$$
\begin{aligned}
\mathbb P (|\frac{S_n}{n}- \frac {\mathbb E [\hat S_n]}{n}| \ge \epsilon )
&=\mathbb P (|\frac{S_n}{n}- \frac {\mathbb E [\hat S_n]}{n}| \ge \epsilon ,S_n =\hat S_n)
+\mathbb P (|\frac{S_n}{n}- \frac {\mathbb E [\hat S_n]}{n}| \ge \epsilon ,S_n \neq\hat S_n)\\
& \le \mathbb P (|\frac{ \hat S_n}{n}- \frac {\mathbb E [\hat S_n]}{n}| \ge \epsilon )
+ \mathbb P(S_n \neq\hat S_n) 
\end{aligned}
$$

注意到
$$
\begin{aligned}
\mathbb P(S_n \neq\hat S_n) 
&=\mathbb P(\bigcup_{k=1}^n \{X_{nk}\neq X_k\})\\
&\le \sum_{k=1}^n \mathbb P(X_{nk}\neq X_k)\\
& \le \sum_{k=1}^n \mathbb P(X_k> n)\\
&= n\mathbb P(X_1 >n )\\
&\to 0
\end{aligned}
$$
综上
$$
\mathbb P (|\frac{S_n}{n}- \frac {\mathbb E [\hat S_n]}{n}| \ge \epsilon ) 
\le \mathbb P (|\frac{ \hat S_n}{n}- \frac {\mathbb E [\hat S_n]}{n}| \ge \epsilon )
+ \mathbb P(S_n \neq\hat S_n)  \to 0
$$
此时
$$
a_n = \frac {\mathbb E [\hat S_n]}{n}
=\frac {\sum_{k=1}^n \mathbb E[X_{nk}]}{n}=\mathbb E[X_{n1}]=\mathbb E[X_{1} 1_{\{ |X_1|\le n\}}]\overset{n\to \infty} \to \mathbb E[X_1]
$$



#### 推论

$$
若\mathbb E[X_1]  <\infty，则 \frac{S_n}{n} \overset{\mathbb P}\to a =\mathbb E[X_1]
$$

证明：注意有如下命题
$$
\mathbb E[|X_1|]< \infty \Leftrightarrow \lim_{n\to \infty} \int_{\{|X_1|>n\}} X_1 d\mathbb P 
\to 0 
$$
此时
$$
\lim_{x\to \infty}  x \mathbb P (|X_1| \ge x)=\lim_{x\to \infty} \int_{|X_1|\ge x} x d \mathbb P \le 
\lim_{x\to \infty} \int_{|X_1|\ge x} |X_1| d \mathbb P \to 0
$$
由上一定理可得
$$
\frac{S_n}{n} \overset{\mathbb P}\to  a_n = \mathbb E[X_{n1}]
$$
而
$$
\mathbb E[X_{n1}] \to  \mathbb E[X_{n}]=a
$$
从而
$$
\frac{S_n}{n} \overset{\mathbb P}\to  a
$$



## 3.(强)大数定律(SLLN)

#### 定理7.3.1 (Kolmogrov)

$$
设\{X_n\}相互独立，若\sum_{n=1}^{\infty}\frac{\text{Var}(X_n)}{n^2} < \infty, \\
则\sum_{n=1}^{\infty} \frac{X_n -\mathbb E[X_n]}{n}\ a.s收敛
$$



#### 引理

$$
设\{x_n\}是一列实数，\{a_n\}是一列正数，a_n\uparrow \infty，\\
若\sum_{n=1}^{\infty} \frac{x_n}{a_n}收敛，则\\
\lim_{n\to \infty}\frac {1}{a_n} \sum_{k=1}^n x_k=0
$$



#### 定理7.3.3

$$
设\{X_n\} \ iid，S_n =\sum_{k=1}^n X_k，则\frac{S_n}{n}\overset{a.s}\to 某个有限常数a \Leftrightarrow \\
\mathbb E[X_1]有限，此时a =\mathbb E[X_1]
$$

证明：$\Leftarrow$：定义
$$
\hat X_{n}\triangleq X_n 1_{\{ |X_n|\le n\}} ,\hat S_n =\sum_{k=1}^n \hat  X_{k}
$$
则$\hat X_n$独立，且
$$
\begin{aligned}
\begin{aligned}
  \sum_{n=1}^\infty \frac {\text{Var}(\hat X_{n})} {n^2}
&\le \sum_{n=1}^\infty \frac {\mathbb E[\hat X_{n}^2]} {n^2} \\
&=  \sum_{n=1}^\infty \frac {\mathbb E[X_{n}^21_{\{ |X_n|\le n\}}]} {n^2} \\
&=  \sum_{n=1}^\infty \frac 1 {n^2}\sum_{k=1}^n{\mathbb E[X_{n}^21_{\{k-1\le |X_n|<k\}}]}  \\
&\le  \sum_{n=1}^\infty \frac 1 {n^2}\sum_{k=1}^n k{\mathbb E[|X_{n}|1_{\{k-1\le |X_n|<k\}}]} \\
&\overset{\text{Fubini定理}}
=\sum_{k=1}^\infty (\sum_{n=k}^\infty\frac 1 {n^2})  k {\mathbb E[|X_{1}|1_{\{k-1\le |X_1|<k\}}]}\\
&\le\sum_{k=1}^\infty \frac 2 k  k{\mathbb E[|X_{1}|1_{\{k-1\le |X_1|<k\}}]}\\
&=2\mathbb E[|X_1|]\\
& <\infty
\end{aligned}
\end{aligned}
$$
由定理定理7.3.1可得
$$
\frac{\hat S_n -\mathbb E [\hat S_n]}{n} \overset{a.s}{\to }0
$$
备注：倒数第二个不等号是因为
$$
\frac 1 {n^2}\le \int_{n}^{n+1} \frac 2 {x^2} d x    \\
\sum_{n=k}^\infty\frac 1 {n^2}
<\sum_{n=k}^\infty\int_{n}^{n+1}\frac 2 {x^2} d x  =\int_{k}^{\infty}\frac 2 {x^2} d x
= \frac 2 k
$$
回顾之前的结论
$$
\sum_{n=1}^{\infty} \mathbb P(|X_1| >n) \le \mathbb E[|X|] \le 1 +\sum_{n=1}^{\infty} \mathbb P(|X_1| >n)
$$
所以
$$
\sum_{n=1}^{\infty}\mathbb P (X_n \neq \hat X_n) =\sum_{n=1}^{\infty} \mathbb P(|X_1| >n)有限
$$
所以由第12讲的B-C引理可得
$$
\mathbb P(X_n \neq \hat X_n发生无穷多次)=0
$$
这说明
$$
\frac{S_n -\mathbb E [\hat S_n]}{n} {\to }0
$$
接下来证明
$$
\frac{\mathbb E [\hat S_n]}{n} {\to } \frac{\mathbb E [ S_n]}{n} = \mathbb E[X_1]
$$
利用定义即可
$$
\begin{aligned}
\frac{\mathbb E [\hat S_n]} n 
& = \frac{{\sum}_{k=1}^{\infty} \mathbb E[X_n ,|X_n|\le k]}{n}\\
&=\frac 1 n \sum_{k=1}^n \mathbb E[X_1,|X_1|\le k]
\end{aligned}
$$
利用控制收敛定理可得
$$
\lim_{k\to \infty} \mathbb E[X_1,|X_1|\le k] = \mathbb E[X_1]
$$
从而
$$
\begin{aligned}
\frac{\mathbb E [\hat S_n]} n 
=\frac 1 n \sum_{k=1}^n \mathbb E[X_1,|X_1|\le k] \overset{n\to \infty}\to  \mathbb E[X_1]
\end{aligned}
$$
结论得证。

$\Rightarrow$：反证法，若$\mathbb E[|X_1|]=+\infty$，那么$\forall A >0$
$$
\begin{aligned}
+\infty
&=\mathbb E[\frac{|X_1|}{A}]\\
&=\int_0^{\infty} \mathbb P(\frac{|X_1|}{A}>x) dx\\
&=\sum_{n=1}^{\infty}\int_{n-1}^{n} \mathbb P(\frac{|X_1|}{A}>x) dx\\
&\le \sum_{n=1}^{\infty}\mathbb P({|X_1|}\ge (n-1){A})
\end{aligned}
$$
所以
$$
\sum_{n=1}^{\infty} \mathbb P({|X_n|}\ge n{A}) =\sum_{n=1}^{\infty} \mathbb P({|X_1|}\ge n{A}) =+\infty
$$
因为$\{{|X_n|}\ge n{A}\}$独立，所以由Borel 0-1律可得（见第12讲）
$$
\mathbb P(\{{|X_n|}\ge n{A}\}发生无穷多次)= 1 \\
$$
注意到
$$
\{|S_n -S_{n-1}| =|X_n|\ge n A \} \Rightarrow \{S_n \ge \frac {nA} 2\}
\bigcup \{S_{n-1} \ge \frac {nA} 2\}
$$
所以
$$
 \mathbb P(\{S_n \ge \frac {nA} 2\}
\bigcup \{S_{n-1} \ge \frac {nA} 2\}发生无穷多次)=1
$$
即
$$
\mathbb P(\{S_n \ge \frac {nA} 2\}
发生无穷多次) =1
$$
从而
$$
\varlimsup_{n\to \infty} \frac{|S_n|}{n} \ge \frac A 2
$$
由$A$的任意性可得
$$
\varlimsup_{n\to \infty} \frac{|S_n|}{n}=+\infty 
$$
这就与条件矛盾，从而$\mathbb E[|X_1|]$有限，$\mathbb E[X_1]$有限，接着利用之前的证明可得
$$
\frac{S_n}{n}\overset{a.s}\to \mathbb E[X_1]
$$
注意条件为
$$
\frac{S_n}{n}\overset{a.s}\to 某个有限常数a 
$$
所以
$$
a =\mathbb E[X_1]
$$



# Chapter 8

## 1.特征函数

### 1.特征函数的定义

定义：
$$
设X是定义在(\Omega,\mathcal F,\mathbb P)上的（一维）r.v,定义其特征函数为：\\
\varphi_X(t)=\varphi(t)= \mathbb E[e^{itX}]= \int_{-\infty}^{\infty} e^{itx} dF(x)=\int_{\mathbb R}
e^{itx} \mu(dx)=  \mathbb E[\cos(tX)] +i\mathbb E[\sin(tX)](t\in \mathbb R)
$$


### 2.特征函数的性质

特征函数有如下性质
$$
\begin{aligned}
&(1) |\varphi(t)|\le 1 = \varphi(0)\\
&(2) \varphi在\mathbb R中一致连续\\
&(3)若X\perp Y，则 \varphi_{X+Y}(t)= \varphi_X(t)\varphi_Y(t) \\
&(4) \varphi_{aX+b}(t) =e^{ibt} \varphi_{X}(at)\\
&(5)若\mathbb E[|X|^n] <\infty，则\forall k \le n,\varphi^{(k)}(t)
=i^k \mathbb E[X^k e^{itX}],\\
&\ \ \ \ \ 特别的，\forall k \le n,\varphi^{(k)}(0)
=i^k \mathbb E[X^k] ,\\
&\ \ \ \ \ 
从而\varphi(t)= 1+i\mathbb E[X]t -\frac{\mathbb E[X^2]}{2}t^2 +...+
\frac{i^n \mathbb E[X^n]}{n!}t^n + o(t^n)
\end{aligned}
$$
(1)证明：
$$
|\varphi(t)|=|\mathbb E[e^{itX}]| \le |\mathbb E[1]| =1 = \varphi(0)
$$
(2)证明：
$$
\begin{aligned}
\sup_t |\varphi(t+h)- \varphi(t)| 
&= \sup_t |\mathbb E[e^{i(t+h)X}-e^{itX}]| \\
&= \sup_t |\mathbb E[e^{itX}(e^{ihX}-1)]| \\
&\le \sup_t \mathbb E|e^{ihX}-1|\\
&\overset {(h\to 0)} \to 0
\end{aligned}
$$
(3)(4)(5)利用定义即可验证



### 3.几个常见分布的特征函数

(1)
$$
0-1分布，X\sim  \left(
 \begin{matrix}
   0 & 1\\
   1-p & p
  \end{matrix}
  \right)，\\
则\varphi_X(t)= pe^{it} +q (q= 1-p)
$$
(2)
$$
二项分布b(n,p),X=\sum_{k=1}^n X_k, X_k \ iid\sim \left(
 \begin{matrix}
   0 & 1\\
   1-p & p
  \end{matrix}
  \right),\\
 则 \varphi_X(t)= (pe^{it} +q)^n
$$
(3)
$$
\text{Possion}分布P(\lambda),\\
则\varphi_X(t)= e^{\lambda (e^{it}-1)}
$$
(4)
$$
X\sim \mathcal N(\mu, \sigma^2), \\
则\varphi_X(t)= e^{i\mu t -\frac {\sigma^2t^2}{2}}
$$
(1)(2)(3)直接利用定义计算即可，这里只证明第(4)个结论。

首先计算标准正态分布的特征函数：
$$
\begin{aligned}
\varphi(t)
&= \frac 1 {\sqrt {2\pi}}\int_{-\infty}^\infty e^{itx} e^{-\frac {x^2} 2} dx \\
&=\frac 1 {\sqrt {2\pi}} \int_{-\infty}^\infty  e^{-\frac {x^2} 2}\cos{(tx)} dx +i
\frac 1 {\sqrt {2\pi}} \int_{-\infty}^\infty  e^{-\frac {x^2} 2}\sin{(tx)} dx \\
&=\frac 1 {\sqrt {2\pi}} \int_{-\infty}^\infty  e^{-\frac {x^2} 2}\cos{(tx)} dx
\end{aligned}
$$
关于$t$求导可得
$$
\begin{aligned}
\varphi'(t)
&=\frac 1 {\sqrt {2\pi}} \int_{-\infty}^\infty  -xe^{-\frac {x^2} 2}\sin{(tx)} dx\\
&=\frac 1 {\sqrt {2\pi}}  \int_{-\infty}^\infty \sin{(tx)} d(e^{-\frac {x^2} 2})\\
&=\frac 1 {\sqrt {2\pi}} \sin{(tx)}e^{-\frac {x^2} 2} \Big |_{-\infty}^{\infty}-
\frac 1 {\sqrt {2\pi}} \int_{-\infty}^\infty t \cos{(tx)}e^{-\frac {x^2} 2} dx \\
&=-
\frac 1 {\sqrt {2\pi}} \int_{-\infty}^\infty t \cos{(tx)}e^{-\frac {x^2} 2} dx \\
&=-t \varphi(t)
\end{aligned}
$$
所以
$$
\frac{d\varphi}{\varphi} = -t dt \\
\varphi(t)= c e^{-\frac {t^2}2} \\
c=\varphi(0)= 1\\
\varphi(t)=e^{-\frac {t^2}2}
$$
一般的，若$X\sim \mathcal N(\mu, \sigma^2)$，则
$$
Y=\frac{X-\mu}{\sigma^2} \sim \mathcal N(0,1) \\
\varphi_X(t) =\varphi_{\sigma Y+ \mu}(t)= e^{i\mu t} \varphi_Y(\sigma t)= e^{i\mu t -\frac {\sigma^2t^2}{2}}
$$

关于特征函数有如下定理：

#### 定理8.1.1(连续性定理)

$$
分布函数与特征函数相互唯一决定
$$



#### 定理8.1.2(唯一性定理)

$$
若\{X, X_n ,n\ge 1\}的特征函数为\{\varphi,\varphi_n ,n\ge 1\}，\\
则 X_n \overset{d}\to X \Leftrightarrow \varphi_n \to \varphi
$$



## 2.多元特征函数

### 1.多元特征函数的定义

定义：
$$
\overset{\to} X= (X_1,...,X_n)^T是n维r.v，定义其特征函数为\\
\begin{aligned}
\varphi(t_1,...,t_n)
&=\mathbb E[e^{i\overset {\to}t^T \overset {\to}  X}]\\
&=\int_{-\infty}^\infty ...\int_{-\infty}^\infty e^{i\sum_{j=1}^n t_j x_j} dF(x_1,...,x_n)\\
&=\int_{-\infty}^\infty ...\int_{-\infty}^\infty e^{i\sum_{j=1}^n t_j x_j} \mu(dx_1...dx_n)\\
\end{aligned}\\
其中\overset {\to}t= (t_1,...,t_n)^T \in \mathbb R^n
$$
利用定义不难计算出
$$
\frac{\partial^{k_1+...+k_n} \varphi(0)}{\partial t_1^{k_1}...\partial t_n^{k_n}} 
=i^{k_1+...+k_n} \mathbb E[X_1^{k_1}... X_n^{k_n}]
$$ {k_1}


### 2.多维Gauss分布

定义：
$$
\overset{\to} X= (X_1,...,X_n)^T服从n维\text{Gauss}分布，如果它的特征函数具有形式：\\
\varphi(t_1,...,t_n) =e^{i\overset {\to} a ^T \overset {\to} t-\frac 1 2 \overset {\to} t^T \Sigma \overset {\to} t}\\
其中\overset {\to}a= (a_1,...,a_n)^T是常数向量，\Sigma =(\sigma_{ij})是n维半正定阵，\\
特别，若|\Sigma|>0，则称\overset{\to} X 服从n维正态分布
$$


#### 性质

$$
\text{Gauss}分布有如下性质：\\
\overset {\to}a= (\mathbb E[X_1],...,\mathbb E[X_n])^T,\Sigma=(\text{Cov}(X_i,X_j))
$$

证明：关于$\varphi(t)$求一次偏导可得
$$
\frac{\partial \varphi(0)}{\partial t_j} =e^{i\overset {\to} a ^T \overset {\to} t-\frac 1 2 \overset {\to} t^T \Sigma \overset {\to} t}(ia_j -\sum_{k=1}^n \sigma_{jk}t_k)\Big |_{t=0}
=ia_j
=i\mathbb E[X_j]
$$
所以
$$
\mathbb E[X_j] =a _j \\
\overset {\to}a= (\mathbb E[X_1],...,\mathbb E[X_n])^T
$$
关于$\varphi(t)$求两次偏导可得
$$
\begin{aligned}
\frac{\partial^{2} \varphi(0)}{\partial t_k\partial t_j} 
&=\frac{\partial}{\partial t_k}\Big(e^{i\overset {\to} a ^T \overset {\to} t-\frac 1 2 \overset {\to} t^T \Sigma \overset {\to} t}(ia_j -\sum_{m=1}^n \sigma_{jm}t_m)\Big)   \\
&= e^{i\overset {\to} a ^T \overset {\to} t-\frac 1 2 \overset {\to} t^T \Sigma \overset {\to} t}(-\sigma_{jk}) + e^{i\overset {\to} a ^T \overset {\to} t-\frac 1 2 \overset {\to} t^T \Sigma \overset {\to} t}(ia_j -\sum_{m=1}^n \sigma_{jm}t_m)(ia_k -\sum_{m=1}^n \sigma_{km}t_m)
\Big |_{t=0} \\
&= -\sigma_{jk} -a_j a_k  \\
&= -\sigma_{jk} -\mathbb E[X_j] \mathbb E[X_k]  \\
&=-\mathbb E[X_jX_k]
\end{aligned}
$$
从而
$$
\sigma_{jk}= \mathbb E[X_jX_k]-\mathbb E[X_j] \mathbb E[X_k]=\text{Cov}(X_j,X_k)\\
\Sigma=(\sigma_{jk})=(\text{Cov}(X_j,X_k))
$$



#### 定理8.1.3

$$
若\overset{\to} X= (X_1,...,X_n)^T\sim \mathcal N(\overset {\to} a,\Sigma)，\\
A=(a_{ij})_{m\times n }, \overset {\to} b = (b_1,...,b_m)^T,\\
则A\overset{\to} X+\overset {\to} b \sim \mathcal N(A\overset {\to}a+ \overset {\to}b, A\Sigma A^T)
$$

证明：利用特征函数的定义
$$
\begin{aligned}
\varphi_{A\overset{\to} X+\overset {\to} b}(t_1,...,t_n)
&=\mathbb E[e^{i\overset {\to}t^T (A\overset{\to} X+\overset {\to} b)}]\\
&= e^{i\overset {\to}t^T\overset {\to} b}\mathbb E[e^{i(A^T\overset {\to}t)^T \overset{\to} X}]\\ 
&= e^{i\overset {\to}t^T\overset {\to} b} e^{i\overset {\to} a ^T A^T\overset {\to}t-\frac 1 2 \overset {\to}  t^T A\overset {\to} \Sigma \overset {\to}  A^T\overset {\to}t} \\
&=\exp \Big(i\overset {\to} b^T\overset {\to}t+ i\overset {\to} a ^T A^T\overset {\to}t-\frac 1 2 \overset {\to}  t^T A\overset {\to} \Sigma \overset {\to}  A^T\overset {\to}t \Big)   \\
&=\exp \Big(i\overset {\to} (A\overset {\to} a +\overset {\to}b)^T\overset {\to}t-\frac 1 2 \overset {\to}  t^T A\overset {\to} \Sigma \overset {\to}  A^T\overset {\to}t \Big) 
\end{aligned}
$$
利用唯一性定理可得
$$
A\overset{\to} X+\overset {\to} b \sim \mathcal N(A\overset {\to}a+ \overset {\to}b, A\Sigma A^T)
$$


#### 定理8.1.4

$$
若\overset{\to} X= (X_1,...,X_n)^T=
 \left(
 \begin{matrix}
   \overset{\to}{X^{(1)}} \\
\overset{\to}{X^{(2)}}
  \end{matrix}
  \right) 
\sim \mathcal N(\overset {\to} a,\Sigma)，\\
 \overset{\to}{X^{(1)}}=(X_1,...,X_k)^T,
 \overset{\to}{X^{(2)}}=(X_{k+1},...,X_n)^T\\
相应地将\Sigma表达为 \left(
 \begin{matrix}
   \Sigma_{11} & \Sigma_{12}  \\
   \Sigma_{21} & \Sigma_{22}
  \end{matrix}
  \right)\\
则\overset{\to}{X^{(1)}} \perp \overset{\to}{X^{(2)}}\Leftrightarrow 
\Sigma_{12}=\Sigma_{21} =0
$$



#### 定理8.1.5

$$
\overset{\to} X= (X_1,...,X_n)^T服从n维\text{Gauss}分布\Leftrightarrow 
\forall \lambda_1,...,\lambda_n, \sum_{j=1}^n \lambda_j X_j服从一维\text{Gauss}分布
$$



## 2.中心极限定理(CLT)

#### 定理8.2.1

$$
设\{X_n\}\ i id，a =\mathbb E[X_1], 0< \sigma^2 =\text{Var}(X_1) <\infty , \\
则\frac{S_n -na}{\sigma \sqrt n} \overset {d}{\to} \mathcal N(0,1)
$$

证明：
$$
\begin{aligned}
\varphi_{\frac{S_n -na}{\sigma \sqrt n}}(t)
&=  \varphi_{{S_n -na}}(\frac t {{\sigma \sqrt n}}) \\
&= (\varphi_{{X_1 -a}}(\frac t {{\sigma \sqrt n}}))^n \\
&=(1-\frac 1 {2n}t^2 +o(\frac {t^2}n))^n \\
&\to e^{-\frac {t^2}2}
\end{aligned}
$$
所以
$$
R_n =\frac{S_n -na}{\sigma \sqrt n} \overset {d}{\to} \mathcal N(0,1)
$$



关于特征函数有如下命题：

#### 命题

$$
若\varphi(t)是特征函数，那么e^{\varphi(t)-1}也是特征函数
$$

证明该结论之前需要利用如下两个结论：
$$
(1)若\varphi_1(t),...,\varphi_n(t)是n个特征函数，那么\sum_{i=1}^n \lambda_i \varphi_i(t)也是特征函数，其中\lambda_i \ge 0,\sum_{i=1}^n \lambda_i=1 \\
(2)若\varphi_1(t),...,\varphi_n(t)是n个特征函数，那么\prod_{i=1}^n\varphi_i(t)是特征函数，\\
特别地，若\varphi(t)是特征函数，那么
\varphi^n(t)是特征函数
$$
结论(1)的证明：

假设$\varphi_i(t)$对应的分布函数为$F_i(x)$，那么$\sum_{i=1}^n \lambda_i F_i(t)$也是分布函数，由定义即可验证其特征函数为$\sum_{i=1}^n \lambda_i \varphi_i(t)$

结论(2)的证明：

假设$\varphi_i(t)$对应的变量为$X_i$，$X_i$相互独立，则$X=\sum_{i=1}^nX_i$的特征函数为$\prod_{i=1}^n\varphi_i(t)$

接下来利用上述结论证明该命题。

证明：将$e^{\varphi(t)-1}$进行泰勒展开可得
$$
e^{\varphi(t)-1} =\frac 1 e \sum_{i=1}^{\infty}\frac 1 {i!} \varphi^i(t)
$$
因此考虑如下函数
$$
\varphi_n(t)= \frac 1 {x_n} \sum_{i=1}^{n}\frac 1 {i!} \varphi^i(t)\\
x_n =\sum_{i=1}^{n}\frac 1 {i!}
$$
不难看出
$$
\frac 1 {x_n} \sum_{i=1}^{n}\frac 1 {i!} =1
$$
所以由之前的结论可知$\varphi_n(t)$是特征函数，注意到
$$
\lim_{n\to\infty}\varphi_n(t) =e^{\varphi(t)-1}
$$
所以由唯一性定理可得存在随机变量$X$，其特征函数为$e^{\varphi(t)-1}$，即$e^{\varphi(t)-1}$是特征函数。




独立不同分布时有如下定理：

#### 定理8.2.2(Lindeberg-Feller定理)

$$
R_n =\sum_{i=1}^n \frac{X_i-a_i}{\sqrt{\sum_{j=1}^n \sigma_j^2}} ,则 \\
R_n \overset {d}\to \mathcal N(0,1)且\lim_{n\to\infty}\max_{1\le j \le n} \frac{\sigma^2_j}{ B_n^2}=0 
\Leftrightarrow \forall\epsilon>0,\lim_{n\to \infty} \frac 1 {B_n^2} \sum_{k=1}^n 
\mathbb E[|X_k-a_k|^21_{\{ |X_k-a_k|\ge \epsilon B_n\}}]=0\\
其中B_n^2 =\sum_{j=1}^n \sigma_j^2 = \text{Var}(S_n)
$$

（备注，这部分是结合课本补充的，老师没有讲，可以忽略）

这里简述下证明思路，首先要利用如下引理：

##### 引理

$$
\forall |z_k|\le 1, |w_k |\le 1\\
\Big|\prod_{k=1}^n z_k-\prod_{k=1}^n w_k\Big| \le \sum_{k=1}^n\Big|z_k-w_k  \Big|
$$

利用归纳法证明该不等式。

$n=1$时显然，假设$n=m-1$时结论成立，$n=m$时
$$
\begin{aligned}
\Big|\prod_{k=1}^m z_k-\prod_{k=1}^m w_k\Big|
&=\Big|\prod_{k=1}^m z_k-\prod_{k=1}^{m-1} z_kw_m+\prod_{k=1}^{m-1} z_kw_m-\prod_{k=1}^m w_k\Big|\\
&=\Big|(z_m-w_m)\prod_{k=1}^{m-1} z_k+w_m(\prod_{k=1}^{m-1} z_k-\prod_{k=1}^{m-1} w_k)\Big|\\
&\le \Big|z_m-w_m\Big|  \Big|\prod_{k=1}^{m-1} z_k\Big|+\Big|w_m\Big|
\Big|\prod_{k=1}^{m-1} z_k-\prod_{k=1}^{m-1} w_k\Big|\\
&\le  \Big|z_m-w_m\Big| + \sum_{k=1}^{m-1}\Big|z_k-w_k  \Big|\\
&=\sum_{k=1}^n\Big|z_k-w_k  \Big|
\end{aligned}
$$
从而结论成立。

由之前的命题可知，
$$
若 \varphi_{Y_i}(t)是特征函数，那么e^{ \varphi_{Y_i}(t)-1}是特征函数，因此e^{\sum_{i=1}^n (\varphi_{Y_i}(t)-1)}是特征函数
$$
所以我们考虑$\prod_{i=1}^n \varphi_{Y_i}(t)-e^{\sum_{i=1}^n (\varphi_{Y_i}(t)-1)}$，注意到
$$
| \varphi_{Y_i}(t)|\le 1,|e^{\varphi_{Y_i}(t)-1}|=e^{\text{Rez}(\varphi_{Y_i}(t)-1)} \le 1
$$
所以利用上述引理可得
$$
|\prod_{i=1}^n \varphi_{Y_i}(t)-e^{\sum_{i=1}^n (\varphi_{Y_i}(t)-1)}|\le 
\sum_{i=1}^n |\varphi_{Y_i}(t)-e^{\varphi_{Y_i}(t)-1}|
$$
接下来计算$\sum_{i=1}^n |\varphi_{Y_i}(t)-e^{\varphi_{Y_i}(t)-1}|$，若上式$\to 0$，那么命题得证，此定理的条件可以推出这点，更具体的部分可以参考课本。





上述定理的条件不好验证，有如下更好验证的条件：

#### 定理8.2.3(李雅普诺夫中心极限定理)

$$
若\exists \delta>0,使得\\
\frac{1}{B_n^{2+\delta}}\sum_{k=1}^n \mathbb E[|X_k-a_k|^{2+\delta}]\to 0(n\to \infty)，\\
则\text{CLT}成立
$$

